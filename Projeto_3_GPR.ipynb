{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pedro Luiz da Costa** - \n",
    "**Rafael Libertini** - \n",
    "**Gabriel Zezze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import subprocess\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa função trata a foto vetorial para ser trabalhada\n",
    "def convert_to_pd(tabela):\n",
    "    tabela = tabela[tabela.recognized]\n",
    "    tabela['timestamp'] = pd.to_datetime(tabela.timestamp)\n",
    "    tabela['drawing'] = tabela['drawing'].apply(json.loads)\n",
    "    return tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "airplane = pd.read_csv('airplane.csv')\n",
    "octopus = pd.read_csv('octopus.csv')\n",
    "airplane = convert_to_pd(airplane)\n",
    "octopus = convert_to_pd(octopus)\n",
    "\n",
    "airplane_simp = airplane[:10000]\n",
    "\n",
    "octopus_simp = octopus[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa função normaliza o index e limpa as colunas desnecessárias\n",
    "def limpa_tabela(tabela):\n",
    "    tabela['array'] = pd.Series()\n",
    "    tabela['array'] = tabela['array'].astype(object)\n",
    "    tabela['index'] = np.arange(0,len(tabela))\n",
    "    tabela = tabela.set_index('index')\n",
    "    tabela = tabela.drop(['countrycode', 'timestamp','key_id'], axis=1)\n",
    "\n",
    "#Essa função converte as fotos vetorias em um png e salva em uma pasta com o nome da classe.\n",
    "def convert_to_png(tabela):\n",
    "    nome=tabela.word[0]\n",
    "    try:\n",
    "        subprocess.Popen(['rm', '-rf', 'fotos/{}'.format(tabela.word[0])])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, drawing in enumerate(tabela.drawing):\n",
    "        for x,y in drawing:\n",
    "            plt.plot(x, -np.array(y), lw=3, color='black')\n",
    "            plt.axis('off')\n",
    "            try:\n",
    "                plt.savefig('fotos/{}/{}{}.png'.format(nome,nome,i), dpi=8)\n",
    "            except:\n",
    "                os.makedirs('fotos/{}'.format(nome))\n",
    "                plt.savefig('fotos/{}/{}{}.png'.format(nome,nome,i), dpi=8)\n",
    "                \n",
    "        plt.gcf().clear()\n",
    "\n",
    "#Essa função le o png gerado pela função acima e cria uma coluna com o array de pixels correspondente.\n",
    "def to_array(tabela):\n",
    "    nome=tabela.word[0]\n",
    "    \n",
    "    for i in range(0,len(tabela)):\n",
    "        img = Image.open('fotos/{}/{}{}.png'.format(nome,nome,i)).convert('L')\n",
    "        arr = np.array(img)\n",
    "        \n",
    "        result = []\n",
    "        [result.extend(el) for el in arr/255]\n",
    "        tabela['array'][i] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "limpa_tabela(airplane_simp)\n",
    "convert_to_png(airplane_simp)\n",
    "to_array(airplane_simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limpa_tabela(octopus_simp)\n",
    "convert_to_png(octopus_simp)\n",
    "to_array(octopus_simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando o treino do teste e embaralhando o DataFrame\n",
    "train = pd.concat([airplane_simp[:5000],octopus_simp[:5000]]).sample(frac=1)\n",
    "test = pd.concat([airplane_simp[5000:6000],octopus_simp[5000:6000]]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8941176470588236, 0.796078431372549, 0.8588235294117647, 0.9215686274509803, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.8274509803921568, 0.6588235294117647, 0.6549019607843137, 0.6588235294117647, 0.7607843137254902, 0.8666666666666667, 0.807843137254902, 0.7294117647058823, 0.6, 0.9725490196078431, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9647058823529412, 0.7568627450980392, 0.6549019607843137, 0.6549019607843137, 0.6627450980392157, 0.8313725490196079, 0.9921568627450981, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9647058823529412, 0.592156862745098, 0.9176470588235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.796078431372549, 0.6509803921568628, 0.6509803921568628, 0.49411764705882355, 0.7843137254901961, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9607843137254902, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9490196078431372, 0.6941176470588235, 0.6509803921568628, 0.6549019607843137, 0.8549019607843137, 1.0, 1.0, 0.5647058823529412, 0.6862745098039216, 0.6862745098039216, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9607843137254902, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6196078431372549, 0.9529411764705882, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.9254901960784314, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9607843137254902, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996078431372549, 0.4980392156862745, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9529411764705882, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9568627450980393, 0.7019607843137254, 0.6431372549019608, 0.6509803921568628, 0.7450980392156863, 0.8980392156862745, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7254901960784313, 0.9137254901960784, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996078431372549, 0.9098039215686274, 0.7568627450980392, 0.6470588235294118, 0.6274509803921569, 0.6470588235294118, 0.9568627450980393, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6392156862745098, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9803921568627451, 0.5568627450980392, 0.9411764705882353, 0.996078431372549, 0.9921568627450981, 0.984313725490196, 0.7098039215686275, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8901960784313725, 0.8509803921568627, 1.0, 1.0, 0.5764705882352941, 0.9921568627450981, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6980392156862745, 0.9333333333333333, 1.0, 1.0, 1.0, 0.6705882352941176, 0.5882352941176471, 0.984313725490196, 1.0, 1.0, 1.0, 1.0, 0.7215686274509804, 0.5725490196078431, 1.0, 1.0, 0.9254901960784314, 0.611764705882353, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8941176470588236, 0.6549019607843137, 1.0, 1.0, 1.0, 0.8980392156862745, 0.6862745098039216, 0.9333333333333333, 0.6823529411764706, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 0.7607843137254902, 0.8588235294117647, 1.0, 1.0, 0.8901960784313725, 0.7294117647058823, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294117647058, 0.6627450980392157, 0.996078431372549, 1.0, 1.0, 0.7764705882352941, 0.6941176470588235, 0.9921568627450981, 1.0, 0.6549019607843137, 0.9607843137254902, 1.0, 1.0, 1.0, 0.6627450980392157, 0.996078431372549, 0.6352941176470588, 1.0, 1.0, 1.0, 0.6549019607843137, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7529411764705882, 0.7333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6313725490196078, 1.0, 1.0, 1.0, 0.9686274509803922, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6549019607843137, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9058823529411765, 0.6196078431372549, 0.8156862745098039, 1.0, 1.0, 1.0, 1.0, 0.803921568627451, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 0.6627450980392157, 0.996078431372549, 1.0, 1.0, 0.6784313725490196, 0.9568627450980393, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9568627450980393, 0.6392156862745098, 0.7098039215686275, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6235294117647059, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 0.7372549019607844, 0.9215686274509803, 1.0, 1.0, 0.9686274509803922, 0.6431372549019608, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9882352941176471, 0.6823529411764706, 0.6549019607843137, 0.9725490196078431, 1.0, 1.0, 1.0, 0.984313725490196, 0.796078431372549, 0.6549019607843137, 0.6313725490196078, 0.8784313725490196, 1.0, 1.0, 1.0, 1.0, 0.9725490196078431, 0.615686274509804, 1.0, 1.0, 0.9725490196078431, 0.6549019607843137, 1.0, 0.9098039215686274, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6980392156862745, 0.9176470588235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9058823529411765, 0.6509803921568628, 0.6431372549019608, 0.9294117647058824, 1.0, 1.0, 1.0, 0.7607843137254902, 0.6431372549019608, 0.6666666666666666, 0.8549019607843137, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9098039215686274, 0.592156862745098, 0.9686274509803922, 1.0, 0.9607843137254902, 0.5764705882352941, 0.9647058823529412, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.9921568627450981, 0.6352941176470588, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8470588235294118, 0.6392156862745098, 0.7333333333333333, 0.9882352941176471, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8588235294117647, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6352941176470588, 0.996078431372549, 1.0, 0.9607843137254902, 0.5803921568627451, 0.9764705882352941, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6274509803921569, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6588235294117647, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9725490196078431, 0.6666666666666666, 1.0, 1.0, 0.8196078431372549, 0.8392156862745098, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9803921568627451, 0.6784313725490196, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8196078431372549, 0.807843137254902, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6588235294117647, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8274509803921568, 0.7254901960784313, 1.0, 1.0, 0.8196078431372549, 0.8431372549019608, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8235294117647058, 0.8352941176470589, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7725490196078432, 0.7333333333333333, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8156862745098039, 0.7764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.792156862745098, 0.6627450980392157, 0.996078431372549, 0.8117647058823529, 0.8431372549019608, 1.0, 1.0, 1.0, 1.0, 0.615686274509804, 0.7764705882352941, 0.8666666666666667, 0.9019607843137255, 0.5333333333333333, 0.984313725490196, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8627450980392157, 0.6431372549019608, 0.6431372549019608, 0.6666666666666666, 0.7019607843137254, 0.6901960784313725, 0.6549019607843137, 0.7137254901960784, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9137254901960784, 0.6431372549019608, 0.6627450980392157, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0, 0.9764705882352941, 0.8823529411764706, 0.792156862745098, 0.7490196078431373, 0.9529411764705882, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.9607843137254902, 0.9647058823529412, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-67fdda0d3df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Acurácia: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8941176470588236, 0.796078431372549, 0.8588235294117647, 0.9215686274509803, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.8274509803921568, 0.6588235294117647, 0.6549019607843137, 0.6588235294117647, 0.7607843137254902, 0.8666666666666667, 0.807843137254902, 0.7294117647058823, 0.6, 0.9725490196078431, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9647058823529412, 0.7568627450980392, 0.6549019607843137, 0.6549019607843137, 0.6627450980392157, 0.8313725490196079, 0.9921568627450981, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9647058823529412, 0.592156862745098, 0.9176470588235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.796078431372549, 0.6509803921568628, 0.6509803921568628, 0.49411764705882355, 0.7843137254901961, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9607843137254902, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9490196078431372, 0.6941176470588235, 0.6509803921568628, 0.6549019607843137, 0.8549019607843137, 1.0, 1.0, 0.5647058823529412, 0.6862745098039216, 0.6862745098039216, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9607843137254902, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6196078431372549, 0.9529411764705882, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.9254901960784314, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9607843137254902, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996078431372549, 0.4980392156862745, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9529411764705882, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9568627450980393, 0.7019607843137254, 0.6431372549019608, 0.6509803921568628, 0.7450980392156863, 0.8980392156862745, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7254901960784313, 0.9137254901960784, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996078431372549, 0.9098039215686274, 0.7568627450980392, 0.6470588235294118, 0.6274509803921569, 0.6470588235294118, 0.9568627450980393, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6392156862745098, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9803921568627451, 0.5568627450980392, 0.9411764705882353, 0.996078431372549, 0.9921568627450981, 0.984313725490196, 0.7098039215686275, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8901960784313725, 0.8509803921568627, 1.0, 1.0, 0.5764705882352941, 0.9921568627450981, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6980392156862745, 0.9333333333333333, 1.0, 1.0, 1.0, 0.6705882352941176, 0.5882352941176471, 0.984313725490196, 1.0, 1.0, 1.0, 1.0, 0.7215686274509804, 0.5725490196078431, 1.0, 1.0, 0.9254901960784314, 0.611764705882353, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8941176470588236, 0.6549019607843137, 1.0, 1.0, 1.0, 0.8980392156862745, 0.6862745098039216, 0.9333333333333333, 0.6823529411764706, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 0.7607843137254902, 0.8588235294117647, 1.0, 1.0, 0.8901960784313725, 0.7294117647058823, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294117647058, 0.6627450980392157, 0.996078431372549, 1.0, 1.0, 0.7764705882352941, 0.6941176470588235, 0.9921568627450981, 1.0, 0.6549019607843137, 0.9607843137254902, 1.0, 1.0, 1.0, 0.6627450980392157, 0.996078431372549, 0.6352941176470588, 1.0, 1.0, 1.0, 0.6549019607843137, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7529411764705882, 0.7333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6313725490196078, 1.0, 1.0, 1.0, 0.9686274509803922, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6549019607843137, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9058823529411765, 0.6196078431372549, 0.8156862745098039, 1.0, 1.0, 1.0, 1.0, 0.803921568627451, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 0.6627450980392157, 0.996078431372549, 1.0, 1.0, 0.6784313725490196, 0.9568627450980393, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9568627450980393, 0.6392156862745098, 0.7098039215686275, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6235294117647059, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 0.7372549019607844, 0.9215686274509803, 1.0, 1.0, 0.9686274509803922, 0.6431372549019608, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9882352941176471, 0.6823529411764706, 0.6549019607843137, 0.9725490196078431, 1.0, 1.0, 1.0, 0.984313725490196, 0.796078431372549, 0.6549019607843137, 0.6313725490196078, 0.8784313725490196, 1.0, 1.0, 1.0, 1.0, 0.9725490196078431, 0.615686274509804, 1.0, 1.0, 0.9725490196078431, 0.6549019607843137, 1.0, 0.9098039215686274, 0.6627450980392157, 1.0, 1.0, 1.0, 0.6980392156862745, 0.9176470588235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9058823529411765, 0.6509803921568628, 0.6431372549019608, 0.9294117647058824, 1.0, 1.0, 1.0, 0.7607843137254902, 0.6431372549019608, 0.6666666666666666, 0.8549019607843137, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9098039215686274, 0.592156862745098, 0.9686274509803922, 1.0, 0.9607843137254902, 0.5764705882352941, 0.9647058823529412, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 0.9921568627450981, 0.6352941176470588, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8470588235294118, 0.6392156862745098, 0.7333333333333333, 0.9882352941176471, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8588235294117647, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6352941176470588, 0.996078431372549, 1.0, 0.9607843137254902, 0.5803921568627451, 0.9764705882352941, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6627450980392157, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6274509803921569, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6588235294117647, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9725490196078431, 0.6666666666666666, 1.0, 1.0, 0.8196078431372549, 0.8392156862745098, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9803921568627451, 0.6784313725490196, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8196078431372549, 0.807843137254902, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6588235294117647, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8274509803921568, 0.7254901960784313, 1.0, 1.0, 0.8196078431372549, 0.8431372549019608, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8235294117647058, 0.8352941176470589, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7725490196078432, 0.7333333333333333, 0.996078431372549, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8156862745098039, 0.7764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.792156862745098, 0.6627450980392157, 0.996078431372549, 0.8117647058823529, 0.8431372549019608, 1.0, 1.0, 1.0, 1.0, 0.615686274509804, 0.7764705882352941, 0.8666666666666667, 0.9019607843137255, 0.5333333333333333, 0.984313725490196, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8627450980392157, 0.6431372549019608, 0.6431372549019608, 0.6666666666666666, 0.7019607843137254, 0.6901960784313725, 0.6549019607843137, 0.7137254901960784, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9137254901960784, 0.6431372549019608, 0.6627450980392157, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0, 0.9764705882352941, 0.8823529411764706, 0.792156862745098, 0.7490196078431373, 0.9529411764705882, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921568627450981, 0.9607843137254902, 0.9647058823529412, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]'"
     ]
    }
   ],
   "source": [
    "X_train = list(train['array'])\n",
    "y_train = list(train['word'])\n",
    "\n",
    "X_test = list(test['array'])\n",
    "y_test = list(test['word'])\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Acurácia: {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se precisar gravar o xlsx\n",
    "#writer = pd.ExcelWriter('flower5K.xlsx', engine='xlsxwriter')\n",
    "#flower.to_excel(writer)\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
